{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f76dbf1",
   "metadata": {},
   "source": [
    "# Step one: Data analysis and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f6146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b619a50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (51490, 61)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['gameId', 'creationTime', 'gameDuration', 'seasonId', 'winner',\n",
       "       'firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron',\n",
       "       'firstDragon', 'firstRiftHerald', 't1_champ1id', 't1_champ1_sum1',\n",
       "       't1_champ1_sum2', 't1_champ2id', 't1_champ2_sum1', 't1_champ2_sum2',\n",
       "       't1_champ3id', 't1_champ3_sum1', 't1_champ3_sum2', 't1_champ4id',\n",
       "       't1_champ4_sum1', 't1_champ4_sum2', 't1_champ5id', 't1_champ5_sum1',\n",
       "       't1_champ5_sum2', 't1_towerKills', 't1_inhibitorKills', 't1_baronKills',\n",
       "       't1_dragonKills', 't1_riftHeraldKills', 't1_ban1', 't1_ban2', 't1_ban3',\n",
       "       't1_ban4', 't1_ban5', 't2_champ1id', 't2_champ1_sum1', 't2_champ1_sum2',\n",
       "       't2_champ2id', 't2_champ2_sum1', 't2_champ2_sum2', 't2_champ3id',\n",
       "       't2_champ3_sum1', 't2_champ3_sum2', 't2_champ4id', 't2_champ4_sum1',\n",
       "       't2_champ4_sum2', 't2_champ5id', 't2_champ5_sum1', 't2_champ5_sum2',\n",
       "       't2_towerKills', 't2_inhibitorKills', 't2_baronKills', 't2_dragonKills',\n",
       "       't2_riftHeraldKills', 't2_ban1', 't2_ban2', 't2_ban3', 't2_ban4',\n",
       "       't2_ban5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the main data\n",
    "df = pd.read_csv('games.csv')\n",
    "\n",
    "print(f'Shape: {df.shape}')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de558e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Annie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Olaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Galio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Twisted Fate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Xin Zhao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>429</td>\n",
       "      <td>Kalista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>432</td>\n",
       "      <td>Bard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>497</td>\n",
       "      <td>Rakan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>498</td>\n",
       "      <td>Xayah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>516</td>\n",
       "      <td>Ornn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id          name\n",
       "0      1         Annie\n",
       "1      2          Olaf\n",
       "2      3         Galio\n",
       "3      4  Twisted Fate\n",
       "4      5      Xin Zhao\n",
       "..   ...           ...\n",
       "133  429       Kalista\n",
       "134  432          Bard\n",
       "135  497         Rakan\n",
       "136  498         Xayah\n",
       "137  516          Ornn\n",
       "\n",
       "[138 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the first champions json\n",
    "import json\n",
    "f = open('champion_info.json')\n",
    "champs = json.load(f)\n",
    "rows = []\n",
    "champs_1_df = pd.DataFrame(columns=['id', 'name'])\n",
    "for champion_id, champion_data in champs['data'].items():\n",
    "    champ_id = int(champion_id)\n",
    "    name = champion_data['name']\n",
    "    rows.append({'id': champ_id, 'name': name})\n",
    "    \n",
    "champs_1_df['name'] = [row['name'] for row in rows]\n",
    "champs_1_df['id'] = [row['id'] for row in rows]\n",
    "\n",
    "f.close()\n",
    "champs_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f85a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>Annie</td>\n",
       "      <td>[Mage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>Olaf</td>\n",
       "      <td>[Fighter, Tank]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3</td>\n",
       "      <td>Galio</td>\n",
       "      <td>[Tank, Mage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4</td>\n",
       "      <td>Twisted Fate</td>\n",
       "      <td>[Mage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>5</td>\n",
       "      <td>Xin Zhao</td>\n",
       "      <td>[Fighter, Assassin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>429</td>\n",
       "      <td>Kalista</td>\n",
       "      <td>[Marksman]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>432</td>\n",
       "      <td>Bard</td>\n",
       "      <td>[Support, Mage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>497</td>\n",
       "      <td>Rakan</td>\n",
       "      <td>[Support]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>498</td>\n",
       "      <td>Xayah</td>\n",
       "      <td>[Marksman]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>516</td>\n",
       "      <td>Ornn</td>\n",
       "      <td>[Tank, Fighter]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id          name                 role\n",
       "57     1         Annie               [Mage]\n",
       "52     2          Olaf      [Fighter, Tank]\n",
       "89     3         Galio         [Tank, Mage]\n",
       "73     4  Twisted Fate               [Mage]\n",
       "112    5      Xin Zhao  [Fighter, Assassin]\n",
       "..   ...           ...                  ...\n",
       "37   429       Kalista           [Marksman]\n",
       "68   432          Bard      [Support, Mage]\n",
       "43   497         Rakan            [Support]\n",
       "5    498         Xayah           [Marksman]\n",
       "47   516          Ornn      [Tank, Fighter]\n",
       "\n",
       "[138 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The second json's structure is a little bit different, the id's are not on the first element\n",
    "# of the tuple, instead, they are inside the second one\n",
    "\n",
    "f = open('champion_info_2.json')\n",
    "champs_2 = json.load(f)\n",
    "rows = []\n",
    "champs_df = pd.DataFrame(columns=['id', 'name'])\n",
    "for _, champion_data in champs_2['data'].items():\n",
    "    # There is one specific dirty data, where the id -1 and the rest is just filled with None\n",
    "    if float(champion_data['id']) < 0:\n",
    "        continue\n",
    "    champ_id = int(champion_data['id'])\n",
    "    name = champion_data['name']\n",
    "    role = champion_data['tags']\n",
    "    rows.append({'id': champ_id, 'name': name, 'role': role})\n",
    "champs_df['name'] = [row['name'] for row in rows]\n",
    "champs_df['id'] = [row['id'] for row in rows]\n",
    "champs_df['role'] = [row['role'] for row in rows]\n",
    "f.close()\n",
    "champs_df.sort_values('id',inplace=True)\n",
    "champs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb97216a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that there arent any null values since the data was previously cleaned by its author\n",
    "df.isna().sum().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f07710",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "248ba230",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distfit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Distribution\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistfit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distfit\n\u001b[0;32m      5\u001b[0m dfit \u001b[38;5;241m=\u001b[39m distfit(todf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m results \u001b[38;5;241m=\u001b[39m dfit\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgameDuration\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distfit'"
     ]
    }
   ],
   "source": [
    "# Distribution\n",
    "from distfit import distfit\n",
    "\n",
    "\n",
    "dfit = distfit(todf=True)\n",
    "results = dfit.fit_transform(df['gameDuration'])\n",
    "\n",
    "dfit.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b607ee",
   "metadata": {},
   "source": [
    "Note that remaked matches are included in this dataframe, so i will remove them. I will remove the match periods from 3 to 15 minutes. Above that ff is possible and actual wins are unlikely. There may be some low-time ff due to disconnect but, in my interpretation, removing them is reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a0e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remake = df[df['gameDuration'] <= 180].shape[0]\n",
    "between_remake_and_surrender = df[((df['gameDuration'] < 900) & (df['gameDuration']>180))].shape[0]\n",
    "\n",
    "print(\"remake: \", remake,\"  between remake and surrender: \", between_remake_and_surrender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfb58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[((df['gameDuration'] < 900) & (df['gameDuration']>180))]\n",
    "\n",
    "df_model = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]-1309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c4ca40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing potential remake matches\n",
    "df = df[~((df['gameDuration'] < 900) & (df['gameDuration']>180))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7854810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting distribution again\n",
    "from distfit import distfit\n",
    "\n",
    "\n",
    "dfit = distfit(todf=True)\n",
    "results = dfit.fit_transform(df['gameDuration'])\n",
    "dfit.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21cc76",
   "metadata": {},
   "source": [
    "### Analyzing champions' win percentage and pick/ban rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e813df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing champions' win percentage and pick/ban rate\n",
    "\n",
    "champs_t1, champs_t2, bans_t1, bans_t2 = [],[],[],[]\n",
    "\n",
    "# Getting columns that contains champions' appearances 'automatically'\n",
    "\n",
    "# When testing, checking whether its alread in champ_t1 became necessary since compyling it twice\n",
    "# would duplicate the list's values\n",
    "for column in df.columns:\n",
    "    if 'id' in column:\n",
    "        if 't1' in column and column not in champs_t1:\n",
    "            champs_t1.append(column)\n",
    "        elif 't2' in column and column not in champs_t2:\n",
    "            champs_t2.append(column)\n",
    "    if 'ban' in column:\n",
    "        if 't1' in column and column not in bans_t1:\n",
    "            bans_t1.append(column)\n",
    "        elif 't2' in column and column not in bans_t2:\n",
    "            bans_t2.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa438645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting picked/banned percentage and getting the relevance:\n",
    "# how many times a champion is picked when its not banned\n",
    "# (number of picks) / ((total games) - (number of bans))\n",
    "# In my opinion, this number would infer the best bans\n",
    "\n",
    "df['picks'] = df[champs_t1 + champs_t2].values.tolist()\n",
    "df['bans'] = df[bans_t1 + bans_t2].values.tolist()\n",
    "\n",
    "df['comp'] = df[champs_t1 + champs_t2].values.tolist()\n",
    "\n",
    "# I struggled a lot to assign lists/arrays to specific cells, so here's the solution i came up with\n",
    "df['win/lose'] = np.where(df['winner'] == 1, '[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]', '[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]')\n",
    "df['win/lose'] = df['win/lose'].apply(ast.literal_eval)\n",
    "df_exploded = df.explode(['picks','bans','win/lose'])\n",
    "\n",
    "pick_id = df_exploded['picks'].value_counts().reset_index()\n",
    "ban_id = df_exploded['bans'].value_counts().reset_index()\n",
    "winrate_id = df_exploded[['picks','win/lose']].groupby('picks').sum().reset_index()\n",
    "winrate_id.rename(columns={'picks': 'index'},inplace=True)\n",
    "\n",
    "\n",
    "# Since pd.merge only works for 2 dfs, had to do a step inside it\n",
    "df_champion_stats = pd.merge(pick_id,pd.merge(ban_id,winrate_id,on='index'),on='index')\n",
    "df_champion_stats['picked or banned (%)'] = (df_champion_stats['picks'] + df_champion_stats['bans'])*100/df.shape[0]\n",
    "df_champion_stats['relevance (%)'] = df_champion_stats['picks']/(df.shape[0]-df_champion_stats['bans'])*100\n",
    "\n",
    "df_exploded['picks'].value_counts().reset_index()\n",
    "\n",
    "df_champion_stats.rename(columns={'index': 'id'}, inplace= True)\n",
    "df_champion_stats = pd.merge(champs_df,df_champion_stats,on='id')\n",
    "\n",
    "df_champion_stats[['picked or banned (%)', 'relevance (%)']] = df_champion_stats[['picked or banned (%)', 'relevance (%)']].round(2)\n",
    "df_champion_stats.sort_values(by='relevance (%)', ascending = False)\n",
    "df_champion_stats['winrate (%)'] = round(100*df_champion_stats['win/lose']/df_champion_stats['picks'],2)\n",
    "\n",
    "df_champion_stats = df_champion_stats.sort_values('winrate (%)', ascending=False)\n",
    "\n",
    "df_champion_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a64166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: what team composition (i will be based only on roles, since champions would be more specific)\n",
    "# has the highest winrate?\n",
    "df['comp_1'] = df['picks'].apply(lambda x: x[:5])\n",
    "df['comp_2'] = df['picks'].apply(lambda x: x[5:])\n",
    "\n",
    "\n",
    "df[['winner','comp_1','comp_2']]\n",
    "#cel.append(champs_df[champs_df['id'] == df.loc[0,'comp_1'][0]]['role'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since trying to merge array with a dataframe is very tough, i will try it in another way:\n",
    "# exploding it, merging and then making a list again\n",
    "\n",
    "df_comps = df[['gameId','winner','comp_1','comp_2']]\n",
    "df_comps = df_comps.explode(['comp_1','comp_2'])\n",
    "\n",
    "df_comps = pd.merge(df_comps,champs_df.rename(columns={'id': 'comp_1','name':'name_1','role':'role_1'}), on='comp_1', sort=False)\n",
    "\n",
    "\n",
    "df_comps = pd.merge(df_comps,champs_df.rename(columns={'id': 'comp_2','name':'name_2','role':'role_2'}), on='comp_2', sort=False)\n",
    "\n",
    "df_comps = df_comps.sort_values('gameId')\n",
    "\n",
    "# Here comes the tricky part: getting the team comps for each gameId\n",
    "df_comps = df_comps.groupby('gameId').agg(\n",
    "    {'comp_1': list, \n",
    "     'comp_2': list,\n",
    "     'name_1': list,\n",
    "     'name_2': list,\n",
    "     'role_1': lambda x: [x.tolist()], \n",
    "     'role_2': lambda x: [x.tolist()], \n",
    "     'winner': 'first'\n",
    "    }\n",
    ").reset_index()\n",
    "\n",
    "df_comps\n",
    "# Note that the array is nested, so we have to undo it, for that i found a solution online\n",
    "\n",
    "def unnest_array(array):\n",
    "    # Unnest values and sort the role order\n",
    "    # The reason i sorted is to prevent future errors of same composition with different orders\n",
    "    unnested_array = sorted([item for sublist in array for sublist_2 in sublist for item in sublist_2], key=lambda x: x.lower())\n",
    "    # Remove duplicates and return as sorted list\n",
    "    return sorted(list(set(unnested_array)), key=lambda x: x.lower())\n",
    "\n",
    "df_comps['role_1'] = df_comps['role_1'].apply(unnest_array)\n",
    "df_comps['role_2'] = df_comps['role_2'].apply(unnest_array)\n",
    "\n",
    "\n",
    "# Sorting names since pick order doesnt matter:\n",
    "\n",
    "df_comps['name_1'] = df_comps['name_1'].apply(sorted)\n",
    "df_comps['name_2'] = df_comps['name_2'].apply(sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c974be7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_comps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_comps\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_comps' is not defined"
     ]
    }
   ],
   "source": [
    "df_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe6a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most picked roles:\n",
    "df_comps['role_1'] = df_comps['role_1'].astype(str)\n",
    "df_comps['role_2'] = df_comps['role_2'].astype(str)\n",
    "\n",
    "\n",
    "pd.concat([df_comps['role_1'],df_comps['role_2']]).value_counts()\n",
    "\n",
    "df_comps[df_comps['role_1'] == df_comps['role_2']]\n",
    "\n",
    "#df_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most picked heroes compositions:\n",
    "df_comps['name_1'] = df_comps['name_1'].astype(str)\n",
    "df_comps['name_2'] = df_comps['name_2'].astype(str)\n",
    "\n",
    "\n",
    "pd.concat([df_comps['name_1'],df_comps['name_2']]).value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f84308d",
   "metadata": {},
   "source": [
    "Note that i got an information that is pretty odd: the most picked comp only repeated four times. That probably happened since most of the popular heroes either get picked by the other team or banned. \n",
    "\n",
    "In my personal experience, the first comp is pretty odd (i confess that i dont remember what was the time's meta), so that explains why the other teams didnt ban them (vayne and kayle are very specific champions)\n",
    "\n",
    "\n",
    "So i wont even bother to determine the best composition's winrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f182c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating roles winrate\n",
    "# Since the same roles can be picked by both teams, i will remove those cases\n",
    "\n",
    "df_comps_winrate = df_comps[df_comps['role_1'] != df_comps['role_2']]\n",
    "results = pd.DataFrame(columns={\"comp\", \"winner\"})\n",
    "\n",
    "for index, row in df_comps_winrate.iterrows():\n",
    "    if row['winner'] == 1:\n",
    "        line = pd.DataFrame({\"comp\": [row['role_1'], row['role_2']],\n",
    "                             \"winner\": [1, 0]})\n",
    "        pd.concat([results,line], ignore_index = True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another approach\n",
    "\n",
    "results = pd.DataFrame(columns={\"comp\", \"winner\"})\n",
    "df_comps_winrate = df_comps[df_comps['role_1'] != df_comps['role_2']]\n",
    "\n",
    "results[['comp','winner']] = [df_comps_winrate[df_comps_winrate['winner'] == 1]['role_1'],1]\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518793f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one was a bit crafty. i want to get comp_1 and comp_2 and assure which one was winner\n",
    "# or loser. For that, i used winner % 2 +1 , this way when winner =1 i get 2 and when winner = 2 i get\n",
    "# 1\n",
    "\n",
    "\n",
    "results_data = []\n",
    "for _, row in df_comps_winrate.iterrows():\n",
    "    comp_winner = row['role_' + str(row['winner'])]\n",
    "    comp_loser = row['role_' + str(row['winner'] % 2 + 1)]\n",
    "    \n",
    "    results_data.append({'comp': comp_winner, 'winner': 1})\n",
    "    results_data.append({'comp': comp_loser, 'winner': 0})\n",
    "\n",
    "results = pd.DataFrame(results_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d81754",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('comp').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87041981",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_report = results.groupby('comp').agg({\n",
    "    'winner': ['sum','count']\n",
    "})\n",
    "\n",
    "comp_report['winner','winrate'] = round(100*comp_report['winner']['sum']/comp_report['winner']['count'],2)\n",
    "\n",
    "comp_report.sort_values(('winner','winrate'),ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97487486",
   "metadata": {},
   "source": [
    "What sticks out the most for me was ['Fighter', 'Marksman', 'Tank'], its a pretty unusual composition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc9673",
   "metadata": {},
   "source": [
    "### Starting objectives analysis:\n",
    " - 1st Inhib\n",
    " - 1st Baron\n",
    " - 1st Tower\n",
    " - 1st Dragon\n",
    " - 1st Herald\n",
    " - 1st Blood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without taking 0 values out of the equation\n",
    "df_1st = df.iloc[:,4:11]\n",
    "\n",
    "df_1stwr = pd.DataFrame(columns=df_1st.columns[df_1st.columns != 'winner'] + ' (%)')\n",
    "\n",
    "for column in df_1st.columns[df_1st.columns != 'winner']:\n",
    "    df_1stwr.loc[0,column + ' (%)'] = round(100*df[df['winner'] == df[column]].shape[0]/df.shape[0], 2)\n",
    "\n",
    "df_1stwr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50536b",
   "metadata": {},
   "source": [
    "Those low values can be explained by how often neither teams take barons/herald. So, theses numbers are false. Fixing it now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf18217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking 0 values out of the equation\n",
    "df_1stwr = pd.DataFrame(columns=df_1st.columns[df_1st.columns != 'winner'] + ' (%)')\n",
    "\n",
    "for column in df_1st.columns[df_1st.columns != 'winner']:\n",
    "    df_1stwr.loc[0,column + ' (%)'] = round(100*df[((df['winner'] == df[column]) & \\\n",
    "                                                  (df[column] != 0))].shape[0] / \\\n",
    "                                       df[df[column] != 0].shape[0], 2)\n",
    "\n",
    "df_1stwr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249635ec",
   "metadata": {},
   "source": [
    "I have an idea of some kind of visualization to prove the importance of each objective, i will graphically show three scenarios:\n",
    "1) Enemy team taking the 1st objective\n",
    "\n",
    "\n",
    "2) None of the team taking it\n",
    "\n",
    "\n",
    "\n",
    "3) The actual team taking it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4060f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_1stwr = pd.DataFrame()\n",
    "\n",
    "for column in df_1st.columns[df_1st.columns != 'winner']:\n",
    "    for winner in [1, 2]:\n",
    "        # 1st scenario: the team wins the game but the other team takes it\n",
    "        df_1stwr.loc[0, str(winner) + column + ' (3rd)'] = int(round(100 * df[((df['winner'] == winner) & (df[column] != winner))].shape[0] / df[df[column] != winner].shape[0], 0))\n",
    "        \n",
    "        # 2nd scenario: None of the teams take it and the team wins the game\n",
    "        df_1stwr.loc[0, str(winner) + column + ' (2nd)'] = int(round(100 * df[((df['winner'] == winner) & (df[column] == 0))].shape[0] / df[((df['winner'] == winner) & (df[column] == 0))].shape[0], 0)) if df[((df['winner'] == winner) & (df[column] == 0))].shape[0] else 0\n",
    "        \n",
    "        # 3rd scenario: the team wins the game and takes the objective (removing games that none of the teams took it)\n",
    "        df_1stwr.loc[0, str(winner) + column + ' (1st)'] = int(round(100 * df[((df['winner'] == winner) & (df[column] == winner))].shape[0] / df[df[column] == winner].shape[0], 0))\n",
    "\n",
    "df_1stwr.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713089df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1stwr = pd.DataFrame()\n",
    "\n",
    "for column in df_1st.columns[df_1st.columns != 'winner']:\n",
    "    for winner in [1, 2]:\n",
    "        # 1st scenario: the team wins the game but the other team takes it\n",
    "        df_1stwr.loc[0, '[' + str(winner) + ']' + column + ' (3rd)'] = \\\n",
    "        int(round(100 * df[((df['winner'] == winner) & (df[column] != winner))].shape[0] \n",
    "                  / df[df[column] != winner].shape[0], 0))\n",
    "        \n",
    "        # 2nd scenario: None of the teams take it and the team wins the game\n",
    "        \n",
    "        # The if statement below is to avoid divided by 0 in first blood cases \n",
    "        # (since i removed the remake matches, there hasnt been one that ended without a kill)\n",
    "        df_1stwr.loc[0, '[' + str(winner) + ']' + column + ' (2nd)'] = \\\n",
    "        int(round(100 * df[((df['winner'] == winner) & (df[column] == 0))].shape[0] \n",
    "                  / df[df[column] == 0].shape[0], 0)) if df[df[column] == 0].shape[0] else 0\n",
    "        \n",
    "        # 3rd scenario: the team wins the game and takes the objective (removing games that\n",
    "        # none of the teams took it)\n",
    "        df_1stwr.loc[0, '[' + str(winner) + ']' + column + ' (1st)'] = \\\n",
    "        int(round(100 * df[((df['winner'] == winner) & (df[column] == winner))].shape[0] \n",
    "                  / df[df[column] == winner].shape[0], 0))\n",
    "\n",
    "df_1stwr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755213c7",
   "metadata": {},
   "source": [
    "Maybe this was a bit confusing, i will try to graphically show that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1stwr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a331c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def single_objective_analysis(objective):\n",
    "    columns_chosen = [word for word in df_1stwr.columns if objective in word]\n",
    "    \n",
    "    df_graph = df_1stwr[columns_chosen]\n",
    "\n",
    "    data = np.concatenate((df_graph.iloc[:3].values, df_graph.iloc[3:6].values), axis=0)\n",
    "\n",
    "    labels = [\"Other team's\", \"Neither team's\", \"Actual team's\"]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.3\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, data[0, :3], width, label='Team 1', alpha=0.7)\n",
    "    bars2 = ax.bar(x + width/2, data[0, -3:], width, label='Team 2', alpha=0.7)\n",
    "    \n",
    "    ax.set_ylabel('Percentage')\n",
    "    ax.set_xlabel(objective)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    # Add percentage labels on each bar\n",
    "    for bar1, bar2 in zip(bars1, bars2):\n",
    "        ax.text(bar1.get_x() + bar1.get_width() / 2, bar1.get_height(), f'{int(bar1.get_height())}%', ha='center', va='bottom')\n",
    "        ax.text(bar2.get_x() + bar2.get_width() / 2, bar2.get_height(), f'{int(bar2.get_height())}%', ha='center', va='bottom')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3eac4",
   "metadata": {},
   "source": [
    "This graph emphatizes the importance of objectives and also alert teams that they should take the objectives, since it'll increase the odds dramatically when compairing neither team getting and one team getting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e004fb26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_1stwr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Creating a single cell with every graph:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m column_names \u001b[38;5;241m=\u001b[39m \u001b[43mdf_1stwr\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      4\u001b[0m values \u001b[38;5;241m=\u001b[39m [name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m column_names]\n\u001b[0;32m      5\u001b[0m unique_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(values))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_1stwr' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating a single cell with every graph:\n",
    "\n",
    "column_names = df_1stwr.columns\n",
    "values = [name.split(\"first\")[1].split(\" (\")[0] for name in column_names]\n",
    "unique_values = list(set(values))\n",
    "unique_values\n",
    "\n",
    "[single_objective_analysis(obj) for obj in unique_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8f6e5",
   "metadata": {},
   "source": [
    "Putting it all in a single cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d04330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_analysis(ax, objective):\n",
    "    columns_chosen = [word for word in df_1stwr.columns if objective in word]\n",
    "    \n",
    "    df_graph = df_1stwr[columns_chosen]\n",
    "\n",
    "    data = np.concatenate((df_graph.iloc[:3].values, df_graph.iloc[3:6].values), axis=0)\n",
    "\n",
    "    labels = [\"Other team's\", \"Neither team's\", \"Actual team's\"]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.3\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, data[0, :3], width, label='Team 1', alpha=0.7)\n",
    "    bars2 = ax.bar(x + width/2, data[0, -3:], width, label='Team 2', alpha=0.7)\n",
    "    \n",
    "    ax.set_ylabel('Percentage')\n",
    "    ax.set_xlabel(objective)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "\n",
    "    # Add percentage labels on each bar\n",
    "    for bar1, bar2 in zip(bars1, bars2):\n",
    "        ax.text(bar1.get_x() + bar1.get_width() / 2, bar1.get_height(), f'{int(bar1.get_height())}%', ha='center', va='bottom')\n",
    "        ax.text(bar2.get_x() + bar2.get_width() / 2, bar2.get_height(), f'{int(bar2.get_height())}%', ha='center', va='bottom')\n",
    "\n",
    "    ax.set_ylim(top=100)\n",
    "  \n",
    "\n",
    "plt.figure(figsize=(17, 8))\n",
    "# Create the subplot grid\n",
    "num_plots = len(unique_values)\n",
    "num_cols = 2\n",
    "num_rows = (num_plots + num_cols - 1) // num_cols\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 10))\n",
    "\n",
    "# Fill the subplots with the graphs\n",
    "for i, objective in enumerate(unique_values):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    if num_rows == 1:\n",
    "        ax = axes[col]\n",
    "    else:\n",
    "        ax = axes[row, col]\n",
    "    objective_analysis(ax, objective)\n",
    "\n",
    "# Adjust the layout of the subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Move the legend outside the axes\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.5), ncol=2)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4023c",
   "metadata": {},
   "source": [
    "OBS: Winning without taking towers/inhibs makes sense since it can be a forfeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfdfcdf",
   "metadata": {},
   "source": [
    "### Correlation between objectives, and objective vs winner (incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66775c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step is to transform them in binary\n",
    "\n",
    "df_binary = pd.DataFrame(columns=['fb', 'ft'])\n",
    "\n",
    "\n",
    "df_binary['fb'] = pd.concat\n",
    "\n",
    "# winner_fb = pd.concat([df[df['winner'] == 1]['t1_towerKills'],df[df['winner'] == 2]['t2_towerKills']])\n",
    "\n",
    "# loser_ft = pd.concat([df[df['winner'] == 1]['t2_towerKills'],df[df['winner'] == 2]['t1_towerKills']])\n",
    "\n",
    "\n",
    "\n",
    "df_binary = df[['firstTower','firstBlood']].replace({1:1,2:0})\n",
    "\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Calcular a correlação de Matthews\n",
    "correlation = matthews_corrcoef(df_binary['firstTower'], df_binary['firstBlood'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066130c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Example data - replace with your own data\n",
    "data = df[['winner', 'firstBlood', 'firstTower', 'firstInhibitor', 'firstBaron', 'firstDragon', 'firstRiftHerald']]\n",
    "\n",
    "# Calculating the chi-square statistic for each pair of variables\n",
    "num_vars = data.shape[1]\n",
    "chi2_matrix = np.zeros((num_vars, num_vars))\n",
    "\n",
    "for i in range(num_vars):\n",
    "    for j in range(num_vars):\n",
    "        contingency_table = pd.crosstab(data.iloc[:, i], data.iloc[:, j])\n",
    "        chi2, _, _, _ = chi2_contingency(contingency_table)\n",
    "        chi2_matrix[i, j] = chi2\n",
    "\n",
    "# Creating the heatmap using seaborn\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "heatmap = sns.heatmap(chi2_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", ax=ax)\n",
    "\n",
    "# Set the colorbar limits\n",
    "#heatmap.collections[0].colorbar.set_clim(0, 10000)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a07270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix of: winner, firstBlood, firstTower, firstInhib, firstBaron, firstDragon, firstHerald"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_towers = pd.concat([df[df['winner'] == 1]['t1_towerKills'],df[df['winner'] == 2]['t2_towerKills']])\n",
    "\n",
    "loser_towers = pd.concat([df[df['winner'] == 1]['t2_towerKills'],df[df['winner'] == 2]['t1_towerKills']])\n",
    "\n",
    "\n",
    "winner_towers = winner_towers.to_frame()\n",
    "\n",
    "winner_towers['winner'] = 1\n",
    "loser_towers = loser_towers.to_frame()\n",
    "loser_towers['winner'] = 0\n",
    "teste = pd.concat([winner_towers,loser_towers])\n",
    "\n",
    "\n",
    "correlation = np.corrcoef(teste[0], teste['winner'])[0, 1]\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777a7d2",
   "metadata": {},
   "source": [
    "### Starting to model: \n",
    "1) Predict the team winner with every piece of information we have on our disposal\n",
    "\n",
    "\n",
    "\n",
    "2) It would be fun (especially for gamblers) to predict the winner with the minimal information available. I will do it using only team picks, bans, first blood, and first tower, as these pieces of information can be seen beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3221c1e",
   "metadata": {},
   "source": [
    "Removing irrelevant columns and separating features from target (winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed16e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['gameId','creationTime','seasonId'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summoner_columns = [columns for columns in df.columns if 'sum' in columns]\n",
    "picks_bans = champs_t1 + champs_t2 + bans_t1 + bans_t2\n",
    "features = df.drop(['winner','picks','bans','comp','win/lose'] + picks_bans + summoner_columns,axis=1)\n",
    "target = df['winner']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c8d472",
   "metadata": {},
   "source": [
    "I personally dont like the following approach, since different pick orders will be interpreted differently, but im curious to get the difference between a model with this problem and without it (for now i thought about sorting the picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653ac5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.columns\n",
    "target = df_model['winner']\n",
    "features = df_model.drop(['seasonId','winner','gameId','creationTime']+bans_t1+bans_t2+sum_columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f56d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def model_and_results(features,target):\n",
    "    \n",
    "    # Separe os dados em conjuntos de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = RandomForestClassifier()  # ou RandomForestClassifier\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Matriz de Confusão:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Acurácia:\", accuracy)\n",
    "\n",
    "\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(\"Precisão:\", precision)\n",
    "\n",
    "\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"F1-Score:\", f1)\n",
    "    \n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # Criar um DataFrame para visualizar as importâncias\n",
    "    importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': importances})\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Imprimir as importâncias das variáveis\n",
    "    print('\\n\\n',importance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16efe25f",
   "metadata": {},
   "source": [
    "Results are incredible! But let's dig a little more. I want to sort the picks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229b2b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model[champs_t1].apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705c1ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_model['comp_1'] = df_model[champs_t1].apply(sorted, axis=1)\n",
    "df_model['comp_2'] = df_model[champs_t2].apply(sorted, axis=1)\n",
    "split_1 = pd.DataFrame(df_model['comp_1'].to_list(), columns = champs_t1)\n",
    "split_2 = pd.DataFrame(df_model['comp_2'].to_list(), columns = champs_t2)\n",
    "\n",
    "split_sorted = pd.concat([split_1,split_2],axis=1)\n",
    "\n",
    "sorted_features = pd.concat([df_model.drop(['gameId','creationTime','winner','seasonId']+champs_t1+champs_t2+bans_t1+bans_t2+summoner_columns,axis=1),split_sorted],axis=1)\n",
    "sorted_features.drop(columns=['picks','comp_1','comp_2'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features.drop(['picks','comp_1','comp_2'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5808628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features.drop(['picks','comp_1','comp_2'],axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae878ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_sorted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d578c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a10b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separe os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(sorted_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier()  # ou RandomForestClassifier\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f39a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Acurácia:\", accuracy)\n",
    "\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precisão:\", precision)\n",
    "\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe28da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_win_prediction = sorted_features[champs_t1+champs_t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ecdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Apenas picks de cada time (em ordem)')\n",
    "\n",
    "model_and_results(sorted_win_prediction,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b6fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Picks with first main objectives')\n",
    "model_and_results(df_model[champs_t1+champs_t2+['firstBlood','firstTower','firstDragon','firstRiftHerald']],target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f27d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Picks with first main objectives')\n",
    "\n",
    "\n",
    "\n",
    "model_and_results(df_model[champs_t1+champs_t2+['firstBlood','firstTower']],target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2db4f",
   "metadata": {},
   "source": [
    "Thats a pretty decent result. With only picks, first blood and first tower, we have 71% accuracy to predict the winner. Let me check if bans are relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bedf62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Picks with first main objectives')\n",
    "model_and_results(df_model[champs_t1+champs_t2+bans_t1+bans_t2+['firstBlood','firstTower']],target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1fd04",
   "metadata": {},
   "source": [
    "It isnt that relevant, but if we have the data then why not?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
